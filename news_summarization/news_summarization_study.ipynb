{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/Reviews.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno -2] Name or\n",
      "[nltk_data]     service not known>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65989</th>\n",
       "      <td>Zuke's is a great natural mini treat. They are...</td>\n",
       "      <td>Zuke's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45048</th>\n",
       "      <td>I have many different flavors of these treats ...</td>\n",
       "      <td>Probably not the best flavor, but good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37005</th>\n",
       "      <td>These cookies are my FAVORITE. Especially grea...</td>\n",
       "      <td>Amazon please bring these back! Sub &amp; Save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>This has made me into a coffee lover!  Very  m...</td>\n",
       "      <td>Breakfast in Bed Coffee K-Cups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57501</th>\n",
       "      <td>This is the one and only Cincinnati Chili mix....</td>\n",
       "      <td>Great Chili</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "65989  Zuke's is a great natural mini treat. They are...   \n",
       "45048  I have many different flavors of these treats ...   \n",
       "37005  These cookies are my FAVORITE. Especially grea...   \n",
       "9017   This has made me into a coffee lover!  Very  m...   \n",
       "57501  This is the one and only Cincinnati Chili mix....   \n",
       "\n",
       "                                          Summary  \n",
       "65989                                      Zuke's  \n",
       "45048     Probably not the best flavor, but good.  \n",
       "37005  Amazon please bring these back! Sub & Save  \n",
       "9017               Breakfast in Bed Coffee K-Cups  \n",
       "57501                                 Great Chili  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10만개 데이터만 사용\n",
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows = 100000)\n",
    "\n",
    "# 전체 데이터 중 Summary 열과 Text 열 만 훈련에 사용\n",
    "data = data[['Text','Summary']]\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# 이 데이터의 Summary는 간단한 것도 많아 중복될 수 있다. 하지만 text는 중복되면 안되기 때문에 text 중복은 제거해줌\n",
    "data.drop_duplicates(subset = ['Text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "# null 제거\n",
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 텍스트 정규화와 불용어 제거 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텍스트 정규화(text normalization)**  \n",
    "- 'it'll'은 'it will'과 같고, 'mustn't과 'must not'은 사실 같은 표현이기 때문에 이런 것들을 통일시켜주어 기계가 덜 학습하게 하여 연산량을 줄임\n",
    "- 참고 : https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화를 위한 사전(dictionary) 구성\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**불용어(stopwords)**  \n",
    "- 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어\n",
    "- NLTK에서 제공하는 불용어 리스트를 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac14/anaconda3/envs/aiffel/lib/python3.7/site-packages/bs4/__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는게 더 좋을 것 같아, 함수에 false로 전달\n",
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgx0lEQVR4nO3de7xVZb3v8c/XG1GJV/QQlxZeS61QluQ5mdH2lJSdxH28QCfRskjSne2sHe7a6e5szsbdRQ+nE4VbA80bOzPZKSWmZhdEF8oW0MylYi7hJZSmeKPA3/5jPCsHi7kmA8a8OOf6vl+v8Vpj/sZl/kbzJb+e8TzjGYoIzMzMttcOzU7AzMxamwuJmZmV4kJiZmaluJCYmVkpLiRmZlaKC4mZmZXiQmJmZqW4kJhVIeloSb+W9KykpyX9StKRzc7L7LVkp2YnYPZaJWkI8GNgGjAf2AV4N7ChmXltC0kCFBGvNDsXa19ukZj17yCAiLgmIjZFxEsRcUtE3C/pQknf791RUoekkLRT+nyHpH9KrZnnJf27pL0kXSXpOUn3SOrIHR+SPi3pYUnrJf1vSftLWpz2ny9pl7TvHpJ+LGmdpGfS+ojcue6QNEPSr4AXgfMkLc1fmKTzJP2onv/j2cDhQmLWv98CmyTNk/QBSXts4/GTgNOA4cD+wGLge8CewIPABX32nwCMBY4C/g6YA/wvYCRwGDA57bdDOs+bgVHAS8C3+pzrNGAqsCswCxgt6a257R8FrtzG6zGryIXErB8R8RxwNBDApcA6SQsk7VvwFN+LiEci4llgIfBIRNwaERuBfwMO77P/RRHxXESsBFYAt0TEo7njD095/SEiro+IFyNiPTADeE+fc82NiJURsTEiNgDXkRUPJB0KdJDdtjMrzYXErIqIeDAizoiIEWStgjcBlxQ8/Knc+ksVPr9xe/aX9HpJ35X0uKTngDuB3SXtmNv/iT7nngd8JPWZnAbMTwXGrDQXErOCIuI3wFyygvIC8Prc5v/SwFTOAw4G3hkRQ4BjUly5fTab1jsi7gL+RDZY4CP4tpbVkAuJWT8kvSV1So9In0eS9VPcBSwDjpE0StJuwPkNTG1XshbKHyXtyZZ9Lf25gqwvZWNE/LJeydnA40Ji1r/1wDuBJZJeICsgK4DzImIRWb/D/cBSGtvfcAkwGPh9yuknBY+7kqw15daI1ZT8YiuzgUHSYGAtcEREPNzsfKx9uEViNnBMA+5xEbFa85PtZgOApFVknfETm5uJtSPf2jIzs1LqdmtL0khJt0t6UNJKSeem+J6SFqWpIBblnxaWdL6kbkkPSTouFx8raXnaNiuNhUfSIEnXpfiS/JQTZmbWGHVrkUgaBgyLiHsl7Uo2smUicAbwdETMlDQd2CMivijpEOAaYBzZQ1+3AgdFxCZJdwPnko1QuRmYFRELJX0aeHtEnCVpEnBiRJxaLa+99947Ojo66nHJZmZta+nSpb+PiKGVttWtjyQi1gBr0vp6SQ+SzTl0AjA+7TYPuAP4Yopfm562fUxSNzAu3dsdEhGLASRdQVaQFqZjLkzn+gHwLUmKKtWxo6ODrq6uml2nmdlAIOnx/rY1ZNRWuuV0OLAE2DcVmd5is0/abTibT+vQk2LD03rf+GbHpPmLngX2qvD9UyV1Sepat25dja7KzMygAYVE0huB64HPpknw+t21QiyqxKsds3kgYk5EdEZE59ChFVtmZma2nepaSCTtTFZEroqIH6bwU6n/pLcfZW2K95BNl91rBLA6xUdUiG92THoPxG7A07W/EjMz6089R20JuAx4MCK+mdu0ADg9rZ8O3JiLT0ojsUYDBwJ3p9tf6yUdlc45pc8xvec6CbitWv+ImZnVXj0fSHwX2XTVyyUtS7G/B2YC8yWdCfwOOBkgIlZKmg88AGwEzo6ITem4aWSzrg4m62RfmOKXAVemjvmnyV4kZGZmDTTgHkjs7OwMj9oyM9s2kpZGRGelbZ5ry8zMSnEhMTOzUlxIzMysFM/+W0Md02+qun3VzOMblImZWeO4RWJmZqW4kJiZWSkuJGZmVooLiZmZleJCYmZmpbiQmJlZKS4kZmZWiguJmZmV4kJiZmaluJCYmVkpLiRmZlaKC4mZmZXiQmJmZqW4kJiZWSl1KySSLpe0VtKKXOw6ScvSsqr3Xe6SOiS9lNv2ndwxYyUtl9QtaZYkpfigdL5uSUskddTrWszMrH/1bJHMBSbkAxFxakSMiYgxwPXAD3ObH+ndFhFn5eKzganAgWnpPeeZwDMRcQBwMXBRXa7CzMyqqlshiYg7gacrbUutilOAa6qdQ9IwYEhELI6IAK4AJqbNJwDz0voPgGN7WytmZtY4zeojeTfwVEQ8nIuNlnSfpJ9LeneKDQd6cvv0pFjvticAImIj8CywV6UvkzRVUpekrnXr1tXyOszMBrxmFZLJbN4aWQOMiojDgc8BV0saAlRqYUT6W23b5sGIORHRGRGdQ4cOLZG2mZn11fB3tkvaCfhrYGxvLCI2ABvS+lJJjwAHkbVARuQOHwGsTus9wEigJ51zN/q5lWZmZvXTjBbJfwd+ExF/uWUlaaikHdP6fmSd6o9GxBpgvaSjUv/HFODGdNgC4PS0fhJwW+pHMTOzBqrn8N9rgMXAwZJ6JJ2ZNk1iy072Y4D7Jf0HWcf5WRHR27qYBvwr0A08AixM8cuAvSR1k90Om16vazEzs/7V7dZWREzuJ35Ghdj1ZMOBK+3fBRxWIf4ycHK5LM3MrCw/2W5mZqW4kJiZWSkuJGZmVkrDh/8OZB3Tb+p326qZxzcwEzOz2nGLxMzMSnEhMTOzUlxIzMysFBcSMzMrxYXEzMxKcSExM7NSXEjMzKwUFxIzMyvFhcTMzEpxITEzs1JcSMzMrBQXEjMzK8WFxMzMSnEhMTOzUur5zvbLJa2VtCIXu1DSk5KWpeWDuW3nS+qW9JCk43LxsZKWp22zJCnFB0m6LsWXSOqo17WYmVn/6tkimQtMqBC/OCLGpOVmAEmHAJOAQ9Mx35a0Y9p/NjAVODAtvec8E3gmIg4ALgYuqteFmJlZ/+pWSCLiTuDpgrufAFwbERsi4jGgGxgnaRgwJCIWR0QAVwATc8fMS+s/AI7tba2YmVnjNKOP5BxJ96dbX3uk2HDgidw+PSk2PK33jW92TERsBJ4F9qr0hZKmSuqS1LVu3braXYmZmTW8kMwG9gfGAGuAb6R4pZZEVIlXO2bLYMSciOiMiM6hQ4duU8JmZlZdQwtJRDwVEZsi4hXgUmBc2tQDjMztOgJYneIjKsQ3O0bSTsBuFL+VZmZmNdLQQpL6PHqdCPSO6FoATEojsUaTdarfHRFrgPWSjkr9H1OAG3PHnJ7WTwJuS/0oZmbWQDvV68SSrgHGA3tL6gEuAMZLGkN2C2oV8CmAiFgpaT7wALARODsiNqVTTSMbATYYWJgWgMuAKyV1k7VEJtXrWszMrH91KyQRMblC+LIq+88AZlSIdwGHVYi/DJxcJkczMyvPT7abmVkpWy0kkk6WtGta/7KkH0o6ov6pmZlZKyjSIvmHiFgv6WjgOLKHAGfXNy0zM2sVRQpJb6f38cDsiLgR2KV+KZmZWSspUkielPRd4BTgZkmDCh5nZmYDQJGCcArwU2BCRPwR2BP4Qj2TMjOz1rHV4b8R8aKktcDRwMNkz3k8XO/EbHMd02/qd9uqmcc3MBMzs80VGbV1AfBF4PwU2hn4fj2TMjOz1lHk1taJwIeBFwAiYjWwaz2TMjOz1lGkkPwpzWEVAJLeUN+UzMyslRQpJPPTqK3dJX0SuJVs5l4zM7NCne1fl/Q+4DngYOArEbGo7pmZmVlLKDRpYyocLh5mZraFfguJpPVUfuOggIiIIXXLyszMWka/hSQiPDLLzMy2qtCtrTTb79FkLZRfRsR9dc3KzMxaRpEHEr9CNuPvXsDewFxJX653YmZm1hqKtEgmA4enNxIiaSZwL/BP9UzMzMxaQ5HnSFYBr8t9HgQ8srWDJF0uaa2kFbnY1yT9RtL9km6QtHuKd0h6SdKytHwnd8xYScsldUuaJUkpPkjSdSm+RFJHoSs2M7OaKlJINgArJc2V9D1gBfB8+kd9VpXj5gIT+sQWAYdFxNuB3/Lq/F0Aj0TEmLSclYvPBqYCB6al95xnAs9ExAHAxcBFBa7FzMxqrMitrRvS0uuOIieOiDv7thIi4pbcx7uAk6qdQ9IwYEhELE6frwAmAguBE4AL064/AL4lSWk6FzMza5AiT7bPq9N3fxy4Lvd5tKT7yJ6g/3JE/AIYDvTk9ulJMdLfJ1KOGyU9SzYg4Pd9v0jSVLJWDaNGjarxZZiZDWxFRm19SNJ9kp6W9Jyk9ZKeK/Olkr5E9l6Tq1JoDTAqIg4HPgdcLWkI2cOPffW2OKpt2zwYMSciOiOic+jQoWVSNzOzPorc2roE+GtgeS1uG0k6HfgQcGzv+SJiA1lfDBGxVNIjwEFkLZARucNHAKvTeg8wEuiRtBOwG/B02fzMzGzbFOlsfwJYUaMiMoHsJVkfjogXc/GhknZM6/uRdao/GhFrgPWSjkqjtaYAN6bDFgCnp/WTgNvcP2Jm1nhFWiR/B9ws6eekVgNARHyz2kGSrgHGA3tL6gEuIBulNQhYlEbx3pVGaB0DfFXSRmATcFZE9LYuppGNABtM1sm+MMUvA66U1E3WEplU4FrMzKzGihSSGcDzZM+S7FL0xBExuUL4sn72vR64vp9tXcBhFeIvAycXzcfMzOqjSCHZMyLeX/dMzMysJRXpI7lVkguJmZlVVKSQnA38JE1hUpPhv2Zm1j6KPJDo95KYmVm/ir6PZA+yIbl/mbwxIu6sV1JmZtY6tlpIJH0COJfsYcBlwFHAYuCv6pqZmZm1hCJ9JOcCRwKPR8R7gcOBdXXNyszMWkaRQvJy7qVWgyLiN8DB9U3LzMxaRZE+kp70AqofkT2R/gyvzndlZmYDXJFRWyem1Qsl3U42OeJP6pqVmZm1jCLTyO8vaVDvR6ADeH09kzIzs9ZRpI/kemCTpAPI5soaDVxd16zMzKxlFCkkr0TERuBE4JKI+FtgWH3TMjOzVlGkkPxZ0mSyd3/8OMV2rl9KZmbWSooUko8B/xWYERGPSRoNfL++aZmZWasoMmrrAeAzuc+PATPrmZSZmbWOIi0SMzOzfrmQmJlZKf0WEklXpr/nbs+JJV0uaa2kFbnYnpIWSXo4/d0jt+18Sd2SHpJ0XC4+VtLytG2W0sveJQ2SdF2KL5HUsT15mplZOdX6SMZKejPwcUlXkD2M+BcR8fRWzj0X+BZwRS42HfhZRMyUND19/qKkQ4BJwKHAm8jeynhQRGwCZgNTgbuAm4EJwELgTOCZiDhA0iTgIuDUAtfcdjqm31R1+6qZxzcoEzMbiKrd2voO2VQobwGW9lm6tnbi9L6SvsXmBGBeWp8HTMzFr42IDakzvxsYJ2kYMCQiFkdEkBWliRXO9QPg2N7WipmZNU6/hSQiZkXEW4HLI2K/iBidW/bbzu/bNyLWpPOvAfZJ8eHAE7n9elJseFrvG9/smPTA5LPAXpW+VNJUSV2Sutat8wz4Zma1VGT47zRJ7wDenUJ3RsT9Nc6jUksiqsSrHbNlMGIOMAegs7Oz4j5mZrZ9ikza+BngKrLWwz7AVZL+Zju/76l0u4r0d22K9wAjc/uNIJuqviet941vdoyknchmJd5av42ZmdVYkeG/nwDeGRFfiYivkL1q95Pb+X0LyKZaIf29MReflEZijSZ7P/zd6fbXeklHpf6PKX2O6T3XScBtqR/FzMwaqMiLrQRsyn3eROXbSpsfJF0DjAf2ltQDXED2RPx8SWcCvwNOBoiIlZLmAw8AG4Gz04gtgGlkI8AGk43WWpjilwFXSuoma4lMKnAtZmZWY0UKyfeAJZJuSJ8nkv0jXlVETO5n07H97D8DmFEh3gUcViH+MqkQmZlZ8xTpbP+mpDuAo8laIh+LiPvqnZiZmbWGIi0SIuJe4N4652JmZi3Ic22ZmVkpLiRmZlZK1UIiaUdJtzYqGTMzaz1VC0kagvuipN0alI+ZmbWYIp3tLwPLJS0CXugNRsRn+j+kPW1tll0zs4GoSCG5KS1mZmZbKPIcyTxJg4FREfFQA3IyM7MWUmTSxv8BLCN7NwmSxkhaUOe8zMysRRQZ/nshMA74I0BELANG1y0jMzNrKUUKycaIeLZPzLPsmpkZUKyzfYWkjwA7SjoQ+Azw6/qmZWZmraJIi+RvgEOBDcA1wHPAZ+uYk5mZtZAio7ZeBL4k6aLsY6yvf1pmZtYqiozaOlLScuB+sgcT/0PS2PqnZmZmraBIH8llwKcj4hcAko4me9nV2+uZmJmZtYYifSTre4sIQET8EvDtLTMzA6oUEklHSDoCuFvSdyWNl/QeSd8G7tjeL5R0sKRlueU5SZ+VdKGkJ3PxD+aOOV9St6SHJB2Xi4+VtDxtmyVpq++SNzOz2qp2a+sbfT5fkFvf7udI0jQrYyCbph54ErgB+BhwcUR8Pb+/pEOASWQjx94E3CrpoDQz8WxgKnAXcDMwAVi4vbmZmdm267eQRMR7G/D9xwKPRMTjVRoTJwDXRsQG4DFJ3cA4SauAIRGxGEDSFcBEXEjMzBpqq53tknYHpgAd+f1rNI38JLJnU3qdI2kK0AWcFxHPAMPJWhy9elLsz2m9b3wLkqaStVwYNWpUDdI2M7NeRTrbbyYrIsuBpbmlFEm7AB8G/i2FZgP7k932WsOrt9YqNVWiSnzLYMSciOiMiM6hQ4eWSdvMzPooMvz3dRHxuTp89weAeyPiKYDevwCSLgV+nD72ACNzx40AVqf4iApxMzNroCItkislfVLSMEl79i41+O7J5G5rSRqW23YisCKtLwAmSRokaTRwIHB3RKwB1ks6Ko3WmgLcWIO8zMxsGxRpkfwJ+BrwJV69dRTAftv7pZJeD7wP+FQu/C+SxqRzr+rdFhErJc0HHgA2AmenEVsA04C5wGCyTnZ3tJuZNViRQvI54ICI+H2tvjTN37VXn9hpVfafAcyoEO8CDqtVXgNVtXfRr5p5fAMzMbNWVOTW1krgxXonYmZmralIi2QTsEzS7WRTyQM1G/5rZmYtrkgh+VFazMzMtlDkfSTzGpGImZm1piJPtj9GhQf9ImK7R22ZmVn7KHJrqzO3/jrgZKAWz5GYmVkb2OqorYj4Q255MiIuAf6q/qmZmVkrKHJr64jcxx3IWii71i0jMzNrKUVubeXfS7KR7KnzU+qSjZmZtZwio7Ya8V4SMzNrUUVubQ0C/idbvo/kq/VLy8zMWkWRW1s3As+SvYNkw1b2NTOzAaZIIRkRERPqnomZmbWkIpM2/lrS2+qeiZmZtaQiLZKjgTPSE+4byF5xGxHx9rpmZmZmLaFIIflA3bMwM7OWVWT47+ONSMTMzFpTkT4SMzOzfjWlkEhaJWm5pGWSulJsT0mLJD2c/u6R2/98Sd2SHpJ0XC4+Np2nW9IsSWrG9ZiZDWTNbJG8NyLGRETv7MLTgZ9FxIHAz9JnJB0CTAIOBSYA35a0YzpmNjAVODAtHqZsZtZgr6VbWycAvS/RmgdMzMWvjYgNEfEY0A2MkzQMGBIRiyMigCtyx5iZWYM0q5AEcIukpZKmpti+EbEGIP3dJ8WHA0/kju1JseFpvW98C5KmSuqS1LVu3boaXoaZmRUZ/lsP74qI1ZL2ARZJ+k2VfSv1e0SV+JbBiDnAHIDOzs6K+5iZ2fZpSoskIlanv2uBG4BxwFPpdhXp79q0ew8wMnf4CGB1io+oEDczswZqeCGR9AZJu/auA+8HVgALgNPTbqeTTRZJik+SNEjSaLJO9bvT7a/1ko5Ko7Wm5I4xM7MGacatrX2BG9JI3Z2AqyPiJ5LuAeZLOhP4Hdm74YmIlZLmAw+QvVjr7IjYlM41DZgLDAYWpsXMzBqo4YUkIh4F3lEh/gfg2H6OmQHMqBDvAg6rdY5mZlZcszrbrUV0TL+p6vZVM49vUCZm9lr1WnqOxMzMWpALiZmZleJCYmZmpbiQmJlZKS4kZmZWiguJmZmV4kJiZmaluJCYmVkpLiRmZlaKC4mZmZXiQmJmZqW4kJiZWSkuJGZmVooLiZmZleJCYmZmpfh9JFY3fpeJ2cDgFomZmZXS8EIiaaSk2yU9KGmlpHNT/EJJT0palpYP5o45X1K3pIckHZeLj5W0PG2bpfQieDMza5xm3NraCJwXEfdK2hVYKmlR2nZxRHw9v7OkQ4BJwKHAm4BbJR0UEZuA2cBU4C7gZmACsLBB12FmZjShRRIRayLi3rS+HngQGF7lkBOAayNiQ0Q8BnQD4yQNA4ZExOKICOAKYGJ9szczs76a2kciqQM4HFiSQudIul/S5ZL2SLHhwBO5w3pSbHha7xuv9D1TJXVJ6lq3bl0tL8HMbMBrWiGR9EbgeuCzEfEc2W2q/YExwBrgG727Vjg8qsS3DEbMiYjOiOgcOnRo2dTNzCynKYVE0s5kReSqiPghQEQ8FRGbIuIV4FJgXNq9BxiZO3wEsDrFR1SIm5lZAzVj1JaAy4AHI+Kbufiw3G4nAivS+gJgkqRBkkYDBwJ3R8QaYL2ko9I5pwA3NuQizMzsL5oxautdwGnAcknLUuzvgcmSxpDdnloFfAogIlZKmg88QDbi6+w0YgtgGjAXGEw2WssjtszMGqzhhSQifknl/o2bqxwzA5hRId4FHFa77KyR/OS7WXvwk+1mZlaKC4mZmZXiQmJmZqW4kJiZWSkuJGZmVooLiZmZleJCYmZmpbiQmJlZKX7VrrUkP8xo9trhFomZmZXiQmJmZqW4kJiZWSkuJGZmVoo7260tVeuMd0e8WW25RWJmZqW4kJiZWSm+tWXWh59RMds2bpGYmVkpLd8ikTQB+L/AjsC/RsTMJqdkbc4d+Waba+lCImlH4P8D7wN6gHskLYiIB5qbmVllLkLWjlq6kADjgO6IeBRA0rXACYALibWcsn0zWzu+Xud2ATRFRLNz2G6STgImRMQn0ufTgHdGxDl99psKTE0fDwYeym3eG/h9A9Jtlna/Pmj/a/T1tb52uMY3R8TQShtavUWiCrEtKmNEzAHmVDyB1BURnbVO7LWi3a8P2v8afX2tr92vsdVHbfUAI3OfRwCrm5SLmdmA1OqF5B7gQEmjJe0CTAIWNDknM7MBpaVvbUXERknnAD8lG/57eUSs3MbTVLzl1Uba/fqg/a/R19f62voaW7qz3czMmq/Vb22ZmVmTuZCYmVkpA7aQSJog6SFJ3ZKmNzufepC0StJyScskdTU7n7IkXS5praQVudiekhZJejj93aOZOZbVzzVeKOnJ9Dsuk/TBZuZYhqSRkm6X9KCklZLOTfG2+B2rXF/b/IaVDMg+kjS1ym/JTa0CTG63qVUkrQI6I6LVH4QCQNIxwPPAFRFxWIr9C/B0RMxM/4dgj4j4YjPzLKOfa7wQeD4ivt7M3GpB0jBgWETcK2lXYCkwETiDNvgdq1zfKbTJb1jJQG2R/GVqlYj4E9A7tYq9hkXEncDTfcInAPPS+jyy/2hbVj/X2DYiYk1E3JvW1wMPAsNpk9+xyvW1tYFaSIYDT+Q+99CeP3YAt0hamqaJaUf7RsQayP4jBvZpcj71co6k+9Otr5a87dOXpA7gcGAJbfg79rk+aMPfsNdALSSFplZpA++KiCOADwBnp9sm1npmA/sDY4A1wDeamk0NSHojcD3w2Yh4rtn51FqF62u73zBvoBaSATG1SkSsTn/XAjeQ3dJrN0+l+9K996fXNjmfmouIpyJiU0S8AlxKi/+OknYm+0f2qoj4YQq3ze9Y6fra7Tfsa6AWkrafWkXSG1JnH5LeALwfWFH9qJa0ADg9rZ8O3NjEXOqi9x/Y5ERa+HeUJOAy4MGI+GZuU1v8jv1dXzv9hpUMyFFbAGn43SW8OrXKjOZmVFuS9iNrhUA2Fc7VrX6Nkq4BxpNNyf0UcAHwI2A+MAr4HXByRLRsZ3U/1zie7JZIAKuAT/X2J7QaSUcDvwCWA6+k8N+T9SO0/O9Y5fom0ya/YSUDtpCYmVltDNRbW2ZmViMuJGZmVooLiZmZleJCYmZmpbiQmJlZKS4k1tYkPV+Hc47Jz96aZnb9fInznZxmi729Nhludx6rJO3dzBysNbmQmG27MUAtpwE/E/h0RLy3huc0axgXEhswJH1B0j1p4rx/TLGO1Bq4NL0/4hZJg9O2I9O+iyV9TdKKNBPCV4FT03slTk2nP0TSHZIelfSZfr5/cno/zApJF6XYV4Cjge9I+lqf/YdJujN9zwpJ707x2ZK6Ur7/mNt/laT/k/LtknSEpJ9KekTSWWmf8emcN0h6QNJ3JG3x74Ckj0q6O333dyXtmJa5KZflkv625E9i7SIivHhp24XsHRCQTREzh2zCzh2AHwPHAB3ARmBM2m8+8NG0vgL4b2l9JrAirZ8BfCv3HRcCvwYGkT2R/gdg5z55vInsie2hZDMN3AZMTNvuIHtvTN/czwO+lNZ3BHZN63vmYncAb0+fVwHT0vrFwP3Aruk716b4eOBlYL90/CLgpNzxewNvBf699xqAbwNTgLHAolx+uzf79/Xy2ljcIrGB4v1puQ+4F3gLcGDa9lhELEvrS4EOSbuT/cP96xS/eivnvykiNkT2ErG1wL59th8J3BER6yJiI3AVWSGr5h7gY+nFVm+L7P0WAKdIujddy6HAIbljeueMWw4siYj1EbEOeDldE8Ddkb2LZxNwDVmLKO9YsqJxj6Rl6fN+wKPAfpL+n6QJQNvN2mvbZ6dmJ2DWIAL+OSK+u1kwe2fEhlxoEzCYyq8aqKbvOfr+t7Wt5yMi7kxT/x8PXJluff0C+DxwZEQ8I2ku8LoKebzSJ6dXcjn1nRep72cB8yLi/L45SXoHcBxwNtlb/z6+rddl7cctEhsofgp8PL0nAknDJfX78qSIeAZYL+moFJqU27ye7JbRtlgCvEfS3spe9TwZ+Hm1AyS9meyW1KVkM8oeAQwBXgCelbQv2btmttW4NPP1DsCpwC/7bP8ZcFLv/z7K3qf+5jSia4eIuB74h5SPmVskNjBExC2S3goszmb65nngo2Sth/6cCVwq6QWyvohnU/x2YHq67fPPBb9/jaTz07ECbo6IrU2VPh74gqQ/p3ynRMRjku4DVpLdavpVke/vYzFZn8/bgDt5dZbo3lwfkPRlsrdr7gD8mawF8hLwvVzn/BYtFhuYPPuvWT8kvTEink/r04FhEXFuk9MqRdJ44PMR8aEmp2JtxC0Ss/4dn1oROwGPk43WMrM+3CIxM7NS3NluZmaluJCYmVkpLiRmZlaKC4mZmZXiQmJmZqX8J1N+eqJ/GZndAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "# 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 시작 토큰과 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 훈련 데이터와 테스트 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25713 51844 42274 ... 49458 64048 64400]\n"
     ]
    }
   ],
   "source": [
    "# encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스 만듬\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 단어 집합(vocaburary) 만들기\n",
    "기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꿔주어야함. 각 단어에 고유한 정수를 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31915\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23682\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8233\n",
      "단어 집합에서 희귀 단어의 비율: 74.20335265549114\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.3949042124136164\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않아요.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8,233으로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36, 81, 24, 87, 298, 269, 2510, 361, 447, 105, 1260, 95, 23, 341, 202, 35, 3241, 656, 70, 14, 4656, 186, 43, 744, 39, 88, 3, 4, 2, 6, 39], [656, 89, 429, 487, 2676, 375, 294, 147, 111, 375, 26, 3, 15, 26, 62, 150, 13, 18, 375, 40, 139, 10, 364, 40, 264, 426, 741, 4, 3, 139, 816, 6768, 986, 387], [574, 913, 89, 27, 6, 574, 319, 622, 262, 130, 914, 91]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10461\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8086\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2375\n",
      "단어 집합에서 희귀 단어의 비율: 77.29662556160979\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.886861015314536\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1], [1, 11, 19, 29, 18, 175, 1282, 102, 269], [1, 6, 20, 29], [1, 32, 5, 131, 1283], [1, 1165, 16]]\n",
      "target\n",
      "decoder  [[2], [11, 19, 29, 18, 175, 1282, 102, 269, 2], [6, 20, 29, 2], [32, 5, 131, 1283, 2], [1165, 16, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1250\n",
      "삭제할 테스트 데이터의 개수 : 356\n",
      "훈련 데이터의 개수 : 51405\n",
      "훈련 레이블의 개수 : 51405\n",
      "테스트 데이터의 개수 : 12807\n",
      "테스트 레이블의 개수 : 12807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssac14/anaconda3/envs/aiffel/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# 요약문의 길이가 1인 경우 삭제\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 패딩하기\n",
    "서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델설계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어텐션 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 25/101 [======>.......................] - ETA: 2:26 - loss: 3.5389"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-60985e3c240f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           batch_size = 512, callbacks=[es], epochs = 50)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# batch_size = 216 일때 훈련속도 매우 느림\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 512, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 인퍼런스 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어볼게요. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외시키고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외시키도록 만들거에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교해보기\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 추출척요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
