{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_path = os.getenv('HOME') + '/aiffel/chatbot/ChatbotData.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리\n",
    "1. 질문과 답변의 쌍을 추출\n",
    "2. 문장에서 단어와 구두점 사이에 공백 추가\n",
    "\n",
    "* 숫자도 빼는 것이 좋은지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 영어 포함 시 소문자 변환, 양쪽 공백 제거\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    # 단어와 구두점 사이 공백 추가\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    \n",
    "    # 한글, 알파벳, .,?!을 제외한 문자 공백으로 대체\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations():\n",
    "    with open(dataset_file_path, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    inputs, outputs = [], []\n",
    "    with open(dataset_file_path) as file:\n",
    "        lines = csv.reader(file)\n",
    "        next(lines)\n",
    "        for line in lines:\n",
    "            inputs.append(preprocess_sentence(line[0]))\n",
    "            outputs.append(preprocess_sentence(line[1]))\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "\n",
      "전처리 후의 11번째 질문 샘플: 가끔 궁금해\n",
      "전처리 후의 11번째 답변 샘플: 그 사람도 그럴 거예요 .\n"
     ]
    }
   ],
   "source": [
    "questions, answers = load_conversations()\n",
    "\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "print()\n",
    "print('전처리 후의 11번째 질문 샘플: {}'.format(questions[11]))\n",
    "print('전처리 후의 11번째 답변 샘플: {}'.format(answers[11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이징  \n",
    "단어장(Vocabulary) 만들기 - SubwordTextEncoder 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8133]\n",
      "END_TOKEN의 번호 : [8134]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어장의 크기 : 8133개 (0-8132)  \n",
    "- 전체 단어장 크기 : 8135개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8135\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정수 인코딩 & 패딩 & start, end token 추가\n",
    "- tokenizer.encode() : 단어 > 정수\n",
    "- tokenizer.decode() : 정수 > 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions 최대 길이 : 16\n",
      "questions 평균 길이 : 3.9391017508246637\n",
      "answers 최대 길이 : 24\n",
      "answers 평균 길이 : 4.716146494121627\n"
     ]
    }
   ],
   "source": [
    "questions_len = [len(s.split()) for s in questions]\n",
    "answers_len = [len(s.split()) for s in answers]\n",
    "print(f'questions 최대 길이 : {np.max(questions_len)}')\n",
    "print(f'questions 평균 길이 : {np.mean(questions_len)}')\n",
    "print(f'answers 최대 길이 : {np.max(answers_len)}')\n",
    "print(f'answers 평균 길이 : {np.mean(answers_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 허용 길이 지정\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "# 정수인코딩, 최대길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 정수 인코딩 과정에서 시작, 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        # 최대 길이 10 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    # 최대 길이 10으로 모든 데이터셋 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8135\n",
      "필터링 후의 질문 샘플 개수: 9128\n",
      "필터링 후의 답변 샘플 개수: 9128\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교사 강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({inputs: (None, 10), dec_inputs: (None, 9)}, {outputs: (None, 9)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positional encoding\n",
    "같은 단어라고 하더라도 포지셔널 인코딩을 해준 경우에는 임베딩 벡터값이 달라지므로, 같은 단어라고 해도 각각 다른 위치에 등장했다는 사실을 모델에 알려줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model\n",
    "        )\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Dot Product Attention\n",
    "내적(dot product)을 통해 단어 벡터 간 유사도를 구한 후에, 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구함\n",
    "\n",
    "- attention : 단어들 간의 유사도를 구하는 매커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)  # # tf.matmul : 두 텐서를 행렬곱한 결과 텐서를 리턴\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Head Attention\n",
    "- 내부적으로는 스케일드 닷 프로덕트 어테션 함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "특정 값들을 가려서 실제 연산에 방해가 되지 않도록 하는 기법\n",
    "\n",
    "### Padding Masking\n",
    "문자의 길이를 맞추기 위해서 패딩을 넣어 처리해준 부분은 실제 의미가 있는 단어가 아니므로 패딩부분을 마스킹하여 가려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0인 위치에서 숫자 1이 나오고, 숫자0이 아닌 위치는 숫자0이 나오게 하는 함수\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look-ahead Masking 다음 단어 가리기\n",
    "RNN은 각 step마다 순서대로 들어가는 반면, 트랜스포머는 문장행렬을 만들어 한 번에 행렬형태로 입력으로 들어가기 때문에 마스킹을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더\n",
    "- 하나의 인코더 층은 2개의 서브 층으로 나뉜다.\n",
    "  - 셀프어텐션(멀티 헤드 어텐션)\n",
    "  - 피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더\n",
    "- 셀프 어텐션\n",
    "- 인코더-디코더 어텐션 : query가 디코더의 벡터, key-value가 인코더의 벡터\n",
    "- 피드 포워드 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "        'query': inputs,\n",
    "        'key': inputs,\n",
    "        'value': inputs,\n",
    "        'mask': look_ahead_mask\n",
    "    })\n",
    "\n",
    "    # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "        'query': attention1,\n",
    "        'key': enc_outputs,\n",
    "        'value': enc_outputs,\n",
    "        'mask': padding_mask\n",
    "    })\n",
    "\n",
    "    # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "    # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 층을 쌓아 디코더 만들기\n",
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask'\n",
    "    )(dec_inputs)\n",
    "\n",
    "    # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "    # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask,\n",
    "        output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask'\n",
    "    )(inputs)\n",
    "\n",
    "    # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 512)    7321088     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 512)    9424384     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8135)   4173255     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,918,727\n",
      "Trainable params: 20,918,727\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512  # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512    # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1  # 드롭아웃 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수\n",
    "레이블인 시퀀스에 패딩이 되어져 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커스텀된 학습률 learning rate\n",
    "Custom Learning rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 5.2159 - accuracy: 0.1267\n",
      "Epoch 2/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 4.0647 - accuracy: 0.2138\n",
      "Epoch 3/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 3.5820 - accuracy: 0.2191\n",
      "Epoch 4/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 3.3440 - accuracy: 0.2303\n",
      "Epoch 5/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 3.1263 - accuracy: 0.2416\n",
      "Epoch 6/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 2.8908 - accuracy: 0.2591\n",
      "Epoch 7/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 2.6347 - accuracy: 0.2861\n",
      "Epoch 8/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 2.3532 - accuracy: 0.3205\n",
      "Epoch 9/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 2.0406 - accuracy: 0.3603\n",
      "Epoch 10/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 1.7151 - accuracy: 0.4042\n",
      "Epoch 11/40\n",
      "143/143 [==============================] - 9s 61ms/step - loss: 1.3908 - accuracy: 0.4490\n",
      "Epoch 12/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 1.0811 - accuracy: 0.4956\n",
      "Epoch 13/40\n",
      "143/143 [==============================] - 9s 63ms/step - loss: 0.8007 - accuracy: 0.5395\n",
      "Epoch 14/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.5654 - accuracy: 0.5775\n",
      "Epoch 15/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.3823 - accuracy: 0.6087\n",
      "Epoch 16/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.2476 - accuracy: 0.6307\n",
      "Epoch 17/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.1630 - accuracy: 0.6442\n",
      "Epoch 18/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.1235 - accuracy: 0.6467\n",
      "Epoch 19/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.1006 - accuracy: 0.6487\n",
      "Epoch 20/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.0902 - accuracy: 0.6492\n",
      "Epoch 21/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.0862 - accuracy: 0.6495\n",
      "Epoch 22/40\n",
      "143/143 [==============================] - 9s 62ms/step - loss: 0.0828 - accuracy: 0.6487\n",
      "Epoch 23/40\n",
      "143/143 [==============================] - 9s 64ms/step - loss: 0.0789 - accuracy: 0.6495\n",
      "Epoch 24/40\n",
      "143/143 [==============================] - 9s 64ms/step - loss: 0.0816 - accuracy: 0.6482\n",
      "Epoch 25/40\n",
      "143/143 [==============================] - 9s 64ms/step - loss: 0.0804 - accuracy: 0.6478\n",
      "Epoch 26/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0813 - accuracy: 0.6477\n",
      "Epoch 27/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0793 - accuracy: 0.6477\n",
      "Epoch 28/40\n",
      "143/143 [==============================] - 9s 64ms/step - loss: 0.0815 - accuracy: 0.6477\n",
      "Epoch 29/40\n",
      "143/143 [==============================] - 9s 66ms/step - loss: 0.0864 - accuracy: 0.6461\n",
      "Epoch 30/40\n",
      "143/143 [==============================] - 9s 66ms/step - loss: 0.0753 - accuracy: 0.6484\n",
      "Epoch 31/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0695 - accuracy: 0.6501\n",
      "Epoch 32/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0615 - accuracy: 0.6519\n",
      "Epoch 33/40\n",
      "143/143 [==============================] - 9s 66ms/step - loss: 0.0621 - accuracy: 0.6519\n",
      "Epoch 34/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0557 - accuracy: 0.6534\n",
      "Epoch 35/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0517 - accuracy: 0.6542\n",
      "Epoch 36/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0484 - accuracy: 0.6555\n",
      "Epoch 37/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0461 - accuracy: 0.6555\n",
      "Epoch 38/40\n",
      "143/143 [==============================] - 9s 65ms/step - loss: 0.0416 - accuracy: 0.6566\n",
      "Epoch 39/40\n",
      "143/143 [==============================] - 9s 66ms/step - loss: 0.0437 - accuracy: 0.6564\n",
      "Epoch 40/40\n",
      "143/143 [==============================] - 9s 64ms/step - loss: 0.0380 - accuracy: 0.6573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa24de4a390>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇 테스트\n",
    "예측(inference) 과정\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331  86  30  5  1059  7  8332]]\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 함수\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 놀러 가고 싶다.\n",
      "출력 : 갈때 저도 같이 가요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'갈때 저도 같이 가요 .'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('놀러 가고 싶다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 몸이 조금 안 좋은 것 같아\n",
      "출력 : 피로를 풀어야 할 것 같아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'피로를 풀어야 할 것 같아요 .'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('몸이 조금 안 좋은 것 같아')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 정말 공부하기 싫다 ㅠㅠ\n",
      "출력 : 잠시 쉬어도 돼요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잠시 쉬어도 돼요 .'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 정말 공부하기 싫다 ㅠㅠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 뭐할까\n",
      "출력 : 저랑 놀아요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저랑 놀아요 .'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 뭐할까')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "모델 전체적 구조를 이해하기 어려웠다.\n",
    "\n",
    "### 프로젝트를 진행하면서 알아낸 점\n",
    "공부하다 트랜스포머가 나오게 된 배경에 대해서 알게 되었다. CNN은 필터가 슬라이딩을 통해 연산하는데 window안에서 local context에 집중하여 문장의 길이가 긴 경우 전체적인 맥락을 잡아내기에는 어려움이 있다. RNN은 이전의 문장들의 특징들을 반영할 수 있는 장점은 있으나 문장이 길어질수록 입력값들의 특징들이 끝까지 반영되기 어려운 단점이 있고, RN은 $x_t$를 제외하고 나머지 요소들을 다 반영하므로 dependency문제가 발생하지는 않으나 각각의 unit마다 연산들을 많이 해야하기 때문에 적용하기에는 무겁다고 한다. 그래서 나온 것이 transformer라고 한다.\n",
    "\n",
    "### 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "**기존 하이퍼파라미터**  \n",
    "- NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수  \n",
    "- D_MODEL = 256  # 인코더와 디코더 내부의 입, 출력의 고정 차원  \n",
    "- NUM_HEADS = 8  # 멀티 헤드 어텐션에서의 헤드 수   \n",
    "- UNITS = 512    # 피드 포워드 신경망의 은닉층의 크기  \n",
    "- DROPOUT = 0.1  # 드롭아웃 비율  \n",
    "- epochs = 20\n",
    "\n",
    "**변경 하이퍼파라미터 및 결과**\n",
    "1. epoch = 40\n",
    "  - loss: 0.0174 - accuracy: 0.6623\n",
    "  - 놀러 가고 싶다. > 저도 데려가 주세요 .\n",
    "  - 몸이 조금 안 좋은 것 같아 > 운동할 맛 나겠어요 .\n",
    "\n",
    "\n",
    "2. epoch = 100\n",
    "  - loss: 0.0046 - accuracy: 0.6642\n",
    "  - 놀러 가고 싶다. > 저도 데려가 주세요 .\n",
    "  - 몸이 조금 안 좋은 것 같아 > 피로를 풀어야 할 것 같아요 .\n",
    "  - 오늘 정말 공부하기 싫다 ㅠㅠ > 잠시 쉬어도 돼요 .\n",
    "\n",
    "\n",
    "3. epoch = 40 / NUM_LAYERS = 5\n",
    "  - loss: 0.1021 - accuracy: 0.6393\n",
    "  - 놀러 가고 싶다. > 주소 알려주세요 .\n",
    "  - 몸이 조금 안 좋은 것 같아 > 계획대로 되는 건 없어요 .\n",
    "  - 오늘 정말 공부하기 싫다 ㅠㅠ > 항상 못해본 건 궁금하더라고요 .\n",
    "\n",
    "\n",
    "4. epoch = 40 / D_MODEL = 512\n",
    "  - loss: 0.0380 - accuracy: 0.6573\n",
    "  - 놀러 가고 싶다. > 갈때 저도 같이 가요 .\n",
    "  - 몸이 조금 안 좋은 것 같아 > 피로를 풀어야 할 것 같아요 .\n",
    "  - 오늘 정말 공부하기 싫다 ㅠㅠ > 잠시 쉬어도 돼요 .\n",
    "\n",
    "\n",
    "epoch를 늘리거나 D_MODEL을 늘렸더니 입력 결과가 꽤나 괜찮았다. 정확도는 65정도에서 크게 개선되지 않았다.\n",
    "  \n",
    "<br>\n",
    "\n",
    "### 자기 다짐\n",
    "모델에 대한 이해도가 아직 부족하다. 조금 더 공부해보고 여러번 따라쳐봐야할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
