{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화리뷰 감정분석 - SentencePiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from konlpy.tag import Mecab\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아마 여러분들은 네이버 영화리뷰 감정분석 태스크를 한 번쯤은 다루어 보았을 것입니다. 한국어로 된 corpus를 다루어야 하므로 주로 KoNLPy에서 제공하는 형태소 분석기를 사용하여 텍스트를 전처리해서 RNN 모델을 분류기로 사용했을 것입니다.  \n",
    "\n",
    "만약 이 문제에서 tokenizer를 sentencepiece로 바꾸어 다시 풀어본다면 더 성능이 좋아질까요? 비교해 보는 것도 흥미로울 것입니다.\n",
    "- 네이버 영화리뷰 감정분석 코퍼스에 sentencepiece를 적용시킨 모델 학습하기\n",
    "- 학습된 모델로 sp_tokenize() 메소드 구현하기\n",
    "- 구현된 토크나이저를 적용하여 네이버 영화리뷰 감정분석 모델을 재학습하기\n",
    "- KoNLPy 형태소 분석기를 사용한 모델과 성능 비교하기\n",
    "- (보너스) SentencePiece 모델의 model_type, vocab_size 등을 변경해 가면서 성능 개선 여부 확인하기\n",
    "- Word Vector는 활용할 필요가 없습니다. 활용이 가능하지도 않을 것입니다.\n",
    "- 머지않아 SentencePiece와 BERT 등의 pretrained 모델을 함께 활용하는 태스크를 다루게 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드\n",
    "```\n",
    "$ wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt  \n",
    "$ wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('~/aiffel/data/e4_sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/data/e4_sentiment_classification/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 50000)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 중복 및 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거\n",
    "train_data.drop_duplicates('document', inplace=True)\n",
    "test_data.drop_duplicates('document', inplace=True)\n",
    "\n",
    "# 결측치 제거 - axis=0 NaN인 행을 제거\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 49157)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. 레이블 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    73342\n",
       "1    72840\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('label').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. 한글, 영어, 공백 제외하고 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    아 더빙.. 진짜 짜증나네요 목소리\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['id'] == 9976970]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글, 영문, 공백 제외한 나머지 문자 공백으로 치환\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z ]\",\" \")\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣A-Za-z ]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    아 더빙   진짜 짜증나네요 목소리\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['id'] == 9976970]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 공백 제거\n",
    "train_data['document'] = train_data['document'].str.replace(' +', ' ')\n",
    "test_data['document'] = test_data['document'].str.replace(' +', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    아 더빙 진짜 짜증나네요 목소리\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['id'] == 9976970]['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 제거\n",
    "train_data.drop_duplicates('document', inplace=True)\n",
    "test_data.drop_duplicates('document', inplace=True)\n",
    "\n",
    "# 결측치 제거 - axis=0 NaN인 행을 제거\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144871, 48792)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4. 토큰화 - Sentencepiece 모델 학습\n",
    "Sentencepiece option\n",
    "- input : 입력 corpus\n",
    "- prefix : 저장할 모델 이름\n",
    "- vocab_size : vocab 개수 (기본 8,000개에 스페셜 토큰 7개를 더해서 8,007개)\n",
    "- max_sentence_length : 문장의 최대 길이\n",
    "- pad_id, pad_piece : pad token id, 값\n",
    "- unk_id, unk_piece : unknown token id, 값\n",
    "- bos_id, bos_piece : begin of sentence token id, 값\n",
    "- eos_id, eos_piece : end of sequence token id, 값\n",
    "- user_defined_symblos : 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에서 텍스트 부분만 추출\n",
    "tmp_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/data/naver.csv'\n",
    "train_data['document'].to_csv(tmp_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 8000\n",
    "model_prefix = 'naver_spm'\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f'--input={tmp_file} --model_prefix={model_prefix} --vocab_size={vocab_size}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-5. 토큰화 - 학습된 모델로 sp_tokenizer() 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus, model_prefix):\n",
    "    tensor = []\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "    \n",
    "    with open(f'./{model_prefix}.vocab', 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "    \n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "    \n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split('\\t')[0]\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "    \n",
    "#     tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    \n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load(f'{model_prefix}.model')\n",
    "\n",
    "X_train, word_index, index_word = sp_tokenize(s, train_data['document'], model_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 763, 24, 1911, 50, 1648]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [s.EncodeAsIds(x) for x in test_data['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2668, 168]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144871, 48792)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-6. 라벨 나눠주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144871 144871\n",
      "48792 48792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train), len(y_train))\n",
    "print(len(X_test), len(y_test))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-7. 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193663\n"
     ]
    }
   ],
   "source": [
    "total_data_text = X_train + X_test\n",
    "print(len(total_data_text))\n",
    "num_tokens = [len(token) for token in total_data_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이 평균 :  15.472578654673324\n",
      "문장 길이 최대 :  134\n",
      "문장 길이 최소 :  0\n",
      "문장 길이 표준편차 :  13.515179433698462\n"
     ]
    }
   ],
   "source": [
    "print('문장 길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장 길이 최대 : ', np.max(num_tokens))\n",
    "print('문장 길이 최소 : ', np.min(num_tokens))\n",
    "print('문장 길이 표준편차 : ', np.std(num_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  42\n",
      "전체 문장의 93.72569876538111%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)*100}%가 maxlen 설정값 이내에 포함됩니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144871 48792\n",
      "144871 48792\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x_train, tmp_y_train = [], []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if 0 < len(X_train[i]) < maxlen:\n",
    "        tmp_x_train.append(X_train[i])\n",
    "        tmp_y_train.append(y_train[i])\n",
    "\n",
    "X_train, y_train = tmp_x_train, tmp_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135295 48792\n",
      "135295 48792\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))\n",
    "print(len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-8. 패딩 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post')\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, list, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train), type(X_test), type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), type(y_train), type(X_test), type(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 네이버 영화리뷰 감정분석 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          128000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 128,881\n",
      "Trainable params: 128,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_vector_dim = 16\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "212/212 [==============================] - 1s 6ms/step - loss: 0.2371 - accuracy: 0.8819 - val_loss: 0.4408 - val_accuracy: 0.8393\n",
      "Epoch 2/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2267 - accuracy: 0.8849 - val_loss: 0.4522 - val_accuracy: 0.8368\n",
      "Epoch 3/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2206 - accuracy: 0.8860 - val_loss: 0.4670 - val_accuracy: 0.8401\n",
      "Epoch 4/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.8887 - val_loss: 0.4564 - val_accuracy: 0.8362\n",
      "Epoch 5/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2106 - accuracy: 0.8911 - val_loss: 0.4788 - val_accuracy: 0.8333\n",
      "Epoch 6/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2044 - accuracy: 0.8944 - val_loss: 0.4772 - val_accuracy: 0.8296\n",
      "Epoch 7/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.2006 - accuracy: 0.8975 - val_loss: 0.4795 - val_accuracy: 0.8226\n",
      "Epoch 8/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1953 - accuracy: 0.9008 - val_loss: 0.5011 - val_accuracy: 0.8282\n",
      "Epoch 9/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9035 - val_loss: 0.5019 - val_accuracy: 0.8236\n",
      "Epoch 10/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1903 - accuracy: 0.9061 - val_loss: 0.5195 - val_accuracy: 0.8302\n",
      "Epoch 11/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1860 - accuracy: 0.9089 - val_loss: 0.5229 - val_accuracy: 0.8250\n",
      "Epoch 12/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9097 - val_loss: 0.5045 - val_accuracy: 0.8219\n",
      "Epoch 13/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9135 - val_loss: 0.5164 - val_accuracy: 0.8224\n",
      "Epoch 14/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1794 - accuracy: 0.9142 - val_loss: 0.5106 - val_accuracy: 0.8206\n",
      "Epoch 15/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9183 - val_loss: 0.5270 - val_accuracy: 0.8236\n",
      "Epoch 16/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9192 - val_loss: 0.5358 - val_accuracy: 0.8202\n",
      "Epoch 17/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1714 - accuracy: 0.9213 - val_loss: 0.5391 - val_accuracy: 0.8208\n",
      "Epoch 18/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1685 - accuracy: 0.9233 - val_loss: 0.5488 - val_accuracy: 0.8187\n",
      "Epoch 19/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1665 - accuracy: 0.9243 - val_loss: 0.5494 - val_accuracy: 0.8197\n",
      "Epoch 20/20\n",
      "212/212 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9269 - val_loss: 0.5615 - val_accuracy: 0.8199\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=512, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525/1525 - 4s - loss: 0.6657 - accuracy: 0.8170\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비교 - KoNLPy 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144871, 48792)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다 평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                       흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                         교도소 이야기구먼 솔직히 재미는 없다 평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_split(sentence):\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in train_data['document']:\n",
    "    mecab_corpus.append(mecab_split(kor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아', '더', '빙', '진짜', '짜증', '나', '네요', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍', '지', '않', '구나'],\n",
       " ['너무', '재', '밓었다그래서보는것을추천한다'],\n",
       " ['교도소', '이야기', '구먼', '솔직히', '재미', '는', '없', '다', '평점', '조정']]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_corpus[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193663\n"
     ]
    }
   ],
   "source": [
    "mecab_train_len_list = [len(token) for token in mecab_corpus]\n",
    "mecab_test_len_list = [len(token) for token in X_test]\n",
    "mecab_num_tokens = mecab_train_len_list + mecab_test_len_list\n",
    "print(len(mecab_num_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이 평균 :  40.47456664411891\n",
      "문장 길이 최대 :  111\n",
      "문장 길이 최소 :  0\n",
      "문장 길이 표준편차 :  42.68243474801159\n"
     ]
    }
   ],
   "source": [
    "print('문장 길이 평균 : ', np.mean(mecab_num_tokens))\n",
    "print('문장 길이 최대 : ', np.max(mecab_num_tokens))\n",
    "print('문장 길이 최소 : ', np.min(mecab_num_tokens))\n",
    "print('문장 길이 표준편차 : ', np.std(mecab_num_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_sequences maxlen :  110\n",
      "전체 문장의 74.80571921327254%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "mecab_max_tokens = np.mean(mecab_num_tokens) + 70\n",
    "mecab_maxlen = int(mecab_max_tokens)\n",
    "print('pad_sequences maxlen : ', mecab_maxlen)\n",
    "print(f'전체 문장의 {np.sum(mecab_num_tokens < mecab_max_tokens) / len(mecab_num_tokens)*100}%가 maxlen 설정값 이내에 포함됩니다.')\n",
    "# 길이가 111인 문장이 약 25% 정도 되어 따로 삭제하지 않고 그대로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab Vocab Size: 51210\n"
     ]
    }
   ],
   "source": [
    "# 형태소 기반 토큰화를 진행한 후, 단어 사전의 길이 확인\n",
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144871"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mecab_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 35,  78, 923,  41, 227,  22,  36, 721,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x_test = mecab_tokenizer.texts_to_sequences(test_data['document'])\n",
    "tmp_x_test = tf.keras.preprocessing.sequence.pad_sequences(tmp_x_test, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([809, 132,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_x_train = mecab_tensor\n",
    "mecab_y_train = np.array(train_data['label'])\n",
    "mecab_x_test = tmp_x_test\n",
    "mecab_y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144871 144871\n",
      "48792 48792\n"
     ]
    }
   ],
   "source": [
    "print(len(mecab_x_train), len(mecab_y_train))\n",
    "print(len(mecab_x_test), len(mecab_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(mecab_x_train), type(mecab_y_train))\n",
    "print(type(mecab_x_test), type(mecab_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   35,    78,   923, ...,     0,     0,     0],\n",
       "       [ 1006,   500,   513, ...,     0,     0,     0],\n",
       "       [   26,   204, 29147, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  152,    90,   194, ...,     0,     0,     0],\n",
       "       [ 1021,     3,     8, ...,     0,     0,     0],\n",
       "       [  180,     3,  1890, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51210\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "ch_max = 0\n",
    "for x in mecab_x_train:\n",
    "    tmp = max(x)\n",
    "    if tmp > ch_max:\n",
    "        ch_max = tmp\n",
    "print(ch_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 16)          819376    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 820,257\n",
      "Trainable params: 820,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "word_vector_dim = 16\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(ch_max+1, word_vector_dim, input_shape=(None,)))\n",
    "model2.add(keras.layers.LSTM(8))\n",
    "model2.add(keras.layers.Dense(8, activation='relu'))\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "227/227 [==============================] - 3s 13ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 2/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 3/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 4/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 5/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6931 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4960\n",
      "Epoch 6/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 7/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 8/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 9/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 10/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 11/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 12/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 13/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6935 - val_accuracy: 0.4960\n",
      "Epoch 14/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 15/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5039\n",
      "Epoch 16/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6932 - accuracy: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 17/20\n",
      "227/227 [==============================] - 3s 11ms/step - loss: 0.6932 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 18/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 19/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5040\n",
      "Epoch 20/20\n",
      "227/227 [==============================] - 3s 12ms/step - loss: 0.6932 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.4960\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_mecab = model2.fit(mecab_x_train, mecab_y_train, epochs=20, batch_size=512, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1525/1525 - 2s - loss: 0.6931 - accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "results_mecab = model2.evaluate(mecab_x_test,  mecab_y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 루브릭\n",
    "|평가문항|상세기준|\n",
    "|:-|:-|\n",
    "|1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?|코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?|\n",
    "|2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?|SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.|\n",
    "|3. SentencePiece의 성능을 다각도로 비교분석하였는가?|SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 처음에는 전처리 2-3, 2-7을 빼고 진행했을 때는 정확도가 5-60정도 밖에 나오지 않았는데 전처리를 바꾸니 확실히 정확도가 2-30프로 정도 올라갔다. 이렇게 전처리의 중요성을 다시 한 번 느낀다.\n",
    "- konlpy와 sentencepiece와 비교해보았을 때 확실히 sentencepiece의 정확도가 더 높았었다.\n",
    "- konlpy(mecab) 공식문서를 확인해봤을 때 vocab size는 따로 지정을 못해주는 것 같다~~(내가 못 찾은 걸 수도)~~. 그래서 모델을 생성할 때 embedding layer의 input_dim을 생성된 vocab size에 맞춰서 넣어주었다. 그래서 사실 sentencepiece와 동일한 상황에서 비교해보고 싶었는데 하지 못한 점이 아쉽다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
