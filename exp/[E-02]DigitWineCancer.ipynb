{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공동 모듈 import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손글씨 분류\n",
    "## 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 42  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 37  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 28  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 40  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# 데이터 준비\n",
    "digits = load_digits()\n",
    "digits_data = digits.data      # Feature Data 지정하기\n",
    "digits_label = digits.target   # Label Data 지정하기\n",
    "# print(digits.target_names)    # Target Names 출력해 보기\n",
    "# print(digits.DESCR)           # 데이터 Describe 해 보기\n",
    "\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가\n",
    "\n",
    "### class\n",
    "- 0-9 정수\n",
    "\n",
    "### 평가지표 : Precision\n",
    "실제 Negative 음성인 데이터를 Positive로 잘못 예측하게 된다면, 해당 클래스의 잘못된 특징이 추가되어 분류기의 예측률이 낮아지게 될 것이다. 때문에 정밀도를 기준으로 비교하는 것이 좋을 듯 하다. 또한 불균형한 데이터가 들어올 수 있어 weighted avg precision을 보면 더 효과적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 와인 분류\n",
    "## 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class_0' 'class_1' 'class_2']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 준비\n",
    "wines = load_wine()\n",
    "wines_data = wines.data         # Feature Data 지정하기\n",
    "wines_label = wines.target      # Label Data 지정하기\n",
    "print(wines.target_names)       # Target Names 출력해 보기\n",
    "# print(wines.DESCR)              # 데이터 Describe 해 보기\n",
    "\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, wines_label, test_size=0.2, random_state=25)\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "classifier = RandomForestClassifier(random_state=32)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가\n",
    "\n",
    "### class\n",
    "- class_0\n",
    "- class_1\n",
    "- class_2\n",
    "\n",
    "### 평가지표 : accuracy  \n",
    "와인은 각 특징에 따라 잘 분류만 해주면 되기 때문에 정확도(전체 개수 중 맞은 것의 개수의 수치)를 고려하였다. 5가지 모델을 테스트해본 결과 RandomForest모델이 100%의 정확도를 보여주었고, 오차행렬을 확인했을 때도 정답을 잘 골라내었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유방암 여부 진단\n",
    "## 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# 데이터 준비\n",
    "cancer = load_breast_cancer()\n",
    "cancer_data = cancer.data         # Feature Data 지정하기\n",
    "cancer_label = cancer.target      # Label Data 지정하기\n",
    "print(cancer.target_names)        # Target Names 출력해 보기 m-악성, b-양성\n",
    "# print(wines.DESCR)             # 데이터 Describe 해 보기\n",
    "\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size=0.2, random_state=7)\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "classifier = LogisticRegression(max_iter=3000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가\n",
    "\n",
    "### class\n",
    "- malignant : 악성\n",
    "- benign : 양성   \n",
    "\n",
    "\n",
    "### 평가지표 : recall   \n",
    "recall은 실제 positive 케이스들에서 진짜 positive로 예층성공한 확률이기 때문에 예측해냈어야 하는 케이스들에서 놓치지 않고 예측해낸 경우를 말하는데, 암은 악성을 양성이라 판단하면 안되기 때문에 recall이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "## 이번 프로젝트에서 어려웠던 점\n",
    "오차행렬을 이해하는 것이 어려웠으며, 케이스마다 어떤 지표를 기준으로 두어야하는지 명확히 감이 오지 않았다.\n",
    "\n",
    "## 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "recall과 precision은 어느정도 감이 잡히나 f1-score는 어떨 때 쓰면 좋은지 잘 이해가 가지 않는다.\n",
    "\n",
    "\n",
    "## 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "- 5가지 모델을 적용하고 테스트한 결과, 가장 좋은 결과만 코드상 남겨놓았다.\n",
    "\n",
    "## 만약에 루브릭 평가관련 지표를 달성하지 못했을 때, 이유에 관한 추정\n",
    "\n",
    "\n",
    "## 자기다짐\n",
    "오차행렬에 대해 90프로이상 이해하고 넘어가기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
