{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위바위보 이미지 분류\n",
    "## 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "데이터의 이미지 개수는 2370 입니다.\n",
      "데이터의 이미지 개수는 990 입니다.\n",
      "Epoch 1/20\n",
      "17/17 [==============================] - 0s 19ms/step - loss: 0.8027 - accuracy: 0.6486 - val_loss: 1.0884 - val_accuracy: 0.4459\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.4307 - accuracy: 0.8511 - val_loss: 1.0061 - val_accuracy: 0.5049\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.2904 - accuracy: 0.9017 - val_loss: 1.0632 - val_accuracy: 0.3727\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1977 - accuracy: 0.9445 - val_loss: 0.9312 - val_accuracy: 0.5527\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1345 - accuracy: 0.9638 - val_loss: 1.0759 - val_accuracy: 0.3544\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0861 - accuracy: 0.9813 - val_loss: 0.7751 - val_accuracy: 0.6470\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0666 - accuracy: 0.9849 - val_loss: 0.7233 - val_accuracy: 0.7173\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0480 - accuracy: 0.9910 - val_loss: 0.6680 - val_accuracy: 0.8158\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0334 - accuracy: 0.9964 - val_loss: 0.7051 - val_accuracy: 0.6906\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0204 - accuracy: 0.9988 - val_loss: 0.5378 - val_accuracy: 0.9142\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0136 - accuracy: 0.9988 - val_loss: 0.5099 - val_accuracy: 0.9198\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.9994 - val_loss: 0.4234 - val_accuracy: 0.9691\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.8425\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.3526 - val_accuracy: 0.9705\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9423\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9606\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 0.9564\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9719\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9662\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 0.9691\n",
      "31/31 - 0s - loss: 0.5951 - accuracy: 0.7687\n",
      "test_loss: 0.5951238870620728 \n",
      "test_accuracy: 0.7686868906021118\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# GPU out of memory 문제로 코드 추가\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "\n",
    "# 모든 파일 사이즈를 동일하게 28*28사이즈로 맞춰준다.\n",
    "def change_file_size(path):\n",
    "    image_dir_path = os.getenv(\"HOME\") + \"/aiffel_project/rock_scissor_paper_classifier/\" + path\n",
    "    images = glob.glob(image_dir_path + \"/*.jpg\")\n",
    "    target_size = (28, 28)\n",
    "\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "\n",
    "    print(f\"{path} 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "# train, test data의 사이즈를 변경해주는 함수\n",
    "# 테스트할 때 1번만 진행되면 되기 때문에 위해 함수로 묶어주었다.\n",
    "def resize_train_test():\n",
    "    for x in ['scissor', 'rock', 'paper']:\n",
    "        train_path = 'train/' + x\n",
    "        test_path = 'test/' + x\n",
    "        change_file_size(train_path)\n",
    "        change_file_size(test_path)\n",
    "\n",
    "\n",
    "# 폴더별 가위 0, 바위 1, 보 2 라벨링\n",
    "def load_data(img_path, len_data):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = len_data  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "\n",
    "    # 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype=np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype=np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path + '/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0  # 가위 : 0\n",
    "        idx = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1  # 바위 : 1\n",
    "        idx = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path + '/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype=np.int32)\n",
    "        imgs[idx, :, :, :] = img  # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2  # 보 : 2\n",
    "        idx = idx + 1\n",
    "\n",
    "    print(\"데이터의 이미지 개수는\", idx, \"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "# train data를 라벨링한 후 정규화 시켜준다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel_project/rock_scissor_paper_classifier/train\"\n",
    "(x_train, y_train) = load_data(image_dir_path, 2370)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "# train data를 train, valid로 나눈다.(비율 70:30)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_norm, y_train, test_size=0.3, random_state=25)\n",
    "\n",
    "# test data를 라벨링한 후 정규화 시켜준다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel_project/rock_scissor_paper_classifier/test\"\n",
    "(x_test, y_test) = load_data(image_dir_path, 990)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "# 모델 설계\n",
    "n_channel_1 = 384\n",
    "n_channel_2 = 128\n",
    "n_dense = 30\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPooling2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "n_train_epoch = 20\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch, validation_data=(x_valid, y_valid), batch_size=100)\n",
    "\n",
    "# 모델 평가하기\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)  # verbose/ 0:silent 1:progress bar 2:one line per epoch\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회고\n",
    "### 이번 프로젝트에서 **어려웠던 점,**\n",
    "train data에서는 97-100프로까지의 정확도를 보이지만 아직도 test data에서는 약 75프로의 정확도만 보이고 있다.  \n",
    "첫 셋팅했을 때 40프로정도를 보였었고, 최대한 끌어올린 것이 약 75프로정도인데 그래도 여전히 overfitting 문제를 해결하지 못했다.\n",
    "\n",
    "### 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n",
    "- 알아낸 점\n",
    "Conv2D layer의 인자로 filter수를 정할 때, $2^n$단위로 증가시키면서 관찰하는 것이 좋다고 하고, 어느 하나가 가장 좋은 정확도를 보이면 그 근처에서 가감하여 적절한 값을 찾아내면 된다고 한다.\n",
    "- 모호한 점\n",
    "  - Convolution층은 몇 개로 구성해야 좋은 걸까?\n",
    "  - 레이어의 순서는 어떻게 되어야 좋고 어떤 게 맞는 걸까?\n",
    "\n",
    "### 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n",
    "1. 데이터셋 분리 train : validation : test = 50 : 20 : 30\n",
    "2. 필터 수 증가\n",
    "\n",
    "```py\n",
    "# 기존\n",
    "n_channel_1 = 15\n",
    "n_channel_2 = 20\n",
    "\n",
    "# 변경\n",
    "n_channel_1 = 384\n",
    "n_channel_2 = 128\n",
    "```\n",
    "\n",
    "3. 학습 반복 횟수(epoch) 증가 10 -> 20\n",
    "4. BatchNormalization 추가\n",
    "\n",
    "위의 순으로 변경하면서 가장 좋게 나온 것을 찾고 그 다음, 그 다음 과정을 수행하였다.\n",
    "\n",
    "### 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.\n",
    "overfitting을 극복하기 위해 위의 시도를 해봤지만 완벽히 극복하지는 못했다.\n",
    "- 데이터의 양이 작아서\n",
    "- 데이터를 고려하는 변수가 많아서\n",
    "\n",
    "### **자기 다짐**\n",
    "overfitting의 원인을 분석할 줄 알아야겠고, 레이어를 구성할 때 어떻게 구성해야 좋은 것인지 공부할 필요가 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
