# 가위바위보 이미지 분류

### data
'Google Teachable Machine'을 이용하여 가위바위보 이미지 생성  

### network
simple CNN

### report
|hyper parameters|train acc|test acc|
|-|-|-|
||||
||||
||||
||||

<br><br>

# 회고
### 이번 프로젝트에서 어려웠던 점
train data에서는 97-100프로까지의 정확도를 보이지만 아직도 test data에서는 약 75프로의 정확도만 보이고 있다.  
첫 셋팅했을 때 40프로정도를 보였었고, 최대한 끌어올린 것이 약 75프로정도인데 그래도 여전히 overfitting 문제를 해결하지 못했다.

### 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점
- 알아낸 점
Conv2D layer의 인자로 filter수를 정할 때, $2^n$단위로 증가시키면서 관찰하는 것이 좋다고 하고, 어느 하나가 가장 좋은 정확도를 보이면 그 근처에서 가감하여 적절한 값을 찾아내면 된다고 한다.
- 모호한 점
  - Convolution층은 몇 개로 구성해야 좋은 걸까?
  - 레이어의 순서는 어떻게 되어야 좋고 어떤 게 맞는 걸까?

### 루브릭 평가 지표를 맞추기 위해 시도한 것들
1. 데이터셋 분리 train : validation : test = 50 : 20 : 30
2. 필터 수 증가

```py
# 기존
n_channel_1 = 15
n_channel_2 = 20

# 변경
n_channel_1 = 384
n_channel_2 = 128
```

3. 학습 반복 횟수(epoch) 증가 10 -> 20
4. BatchNormalization 추가

위의 순으로 변경하면서 가장 좋게 나온 것을 찾고 그 다음, 그 다음 과정을 수행하였다.

### 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정
overfitting을 극복하기 위해 위의 시도를 해봤지만 완벽히 극복하지는 못했다.
- 데이터의 양 부족
- 학습 시간 부족

### 자기 다짐
overfitting의 원인을 분석할 줄 알아야겠고, 레이어를 구성할 때 어떻게 구성해야 좋은 것인지 공부할 필요가 있다.