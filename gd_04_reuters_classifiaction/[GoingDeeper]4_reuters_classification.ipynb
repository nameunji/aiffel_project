{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로이터 뉴스 데이터 카테고리 분류\n",
    "Vocabulary Size를 달리할 때 모델 성능 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# vectorize module\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 모든 단어 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "\n",
      "데이터 출력\n",
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 23406, 28185, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"\\n데이터 출력\")\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "# {'mdbl': 10996, 'fawc': 16260, 'degussa': 12089, ...}\n",
    "\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    \n",
    "# train 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "x_train = decoded\n",
    "\n",
    "# test 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "x_test = decoded\n",
    "\n",
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n",
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()  # DTM 생성\n",
    "tfidf_transformer = TfidfTransformer()  # TF-IDF 생성\n",
    "\n",
    "# train data\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(x_train_dtm.shape)\n",
    "print(tfidfv.shape)\n",
    "\n",
    "# test data\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report()\n",
    "- macro: 단순평균\n",
    "- weighted: 각 클래스에 속하는 표본의 개수로 가중평균\n",
    "- accuracy: 정확도. 전체 학습 데이터의 개수에서 클래스를 정확하게 맞춘 개수의 비율."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.5997328584149599 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)    # 모델 학습\n",
    "\n",
    "predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted),'\\n') #예측값과 실제\n",
    "# print(classification_report(y_test, mod.predict(tfidfv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 시각화\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "    plt.ylabel('label')\n",
    "    plt.xlabel('predicted value')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph_confusion_matrix(mod, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 컴플리먼트 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7649154051647373\n"
     ]
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.813446126447017\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 선형 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7773820124666073\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6211041852181657\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6544968833481746\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8187889581478184\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 2246\n",
      "max_len :  2376\n"
     ]
    }
   ],
   "source": [
    "(rnn_x_train, rnn_y_train), (rnn_x_test, rnn_y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "print(len(rnn_x_train), len(rnn_x_test))\n",
    "max_len = max(len(l) for l in np.concatenate((rnn_x_train, rnn_x_test), axis=0))\n",
    "print('max_len : ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_x_train = pad_sequences(rnn_x_train, maxlen=max_len)\n",
    "rnn_x_test = pad_sequences(rnn_x_test, maxlen=max_len)\n",
    "\n",
    "rnn_y_train = to_categorical(rnn_y_train, num_classes=46)\n",
    "rnn_y_test = to_categorical(rnn_y_test, num_classes=46)\n",
    "\n",
    "rnn_x_train = rnn_x_train[1000:]\n",
    "rnn_y_train = rnn_y_train[1000:]\n",
    "rnn_x_val = rnn_x_train[:1000]\n",
    "rnn_y_val = rnn_y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 302ms/step - loss: 0.0790 - accuracy: 0.3329 - val_loss: 0.0726 - val_accuracy: 0.3260\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.0652 - accuracy: 0.4245 - val_loss: 0.0610 - val_accuracy: 0.4730\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 20s 323ms/step - loss: 0.0590 - accuracy: 0.4902 - val_loss: 0.0568 - val_accuracy: 0.4890\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.0522 - accuracy: 0.5446 - val_loss: 0.0515 - val_accuracy: 0.5600\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 20s 320ms/step - loss: 0.0479 - accuracy: 0.5784 - val_loss: 0.0488 - val_accuracy: 0.5700\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 20s 321ms/step - loss: 0.0461 - accuracy: 0.5923 - val_loss: 0.0473 - val_accuracy: 0.5800\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 20s 323ms/step - loss: 0.0446 - accuracy: 0.6020 - val_loss: 0.0444 - val_accuracy: 0.6210\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 20s 324ms/step - loss: 0.0417 - accuracy: 0.6354 - val_loss: 0.0403 - val_accuracy: 0.6500\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 20s 323ms/step - loss: 0.0384 - accuracy: 0.6621 - val_loss: 0.0379 - val_accuracy: 0.6730\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 20s 319ms/step - loss: 0.0352 - accuracy: 0.6963 - val_loss: 0.0340 - val_accuracy: 0.7150\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 20s 322ms/step - loss: 0.0319 - accuracy: 0.7304 - val_loss: 0.0307 - val_accuracy: 0.7340\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 20s 318ms/step - loss: 0.0286 - accuracy: 0.7590 - val_loss: 0.0269 - val_accuracy: 0.7720\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.0259 - accuracy: 0.7834 - val_loss: 0.0233 - val_accuracy: 0.8190\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.0226 - accuracy: 0.8125 - val_loss: 0.0220 - val_accuracy: 0.8170\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 20s 324ms/step - loss: 0.0201 - accuracy: 0.8345 - val_loss: 0.0185 - val_accuracy: 0.8450\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.0174 - accuracy: 0.8591 - val_loss: 0.0173 - val_accuracy: 0.8740\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.0159 - accuracy: 0.8758 - val_loss: 0.0141 - val_accuracy: 0.8860\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 20s 322ms/step - loss: 0.0137 - accuracy: 0.8959 - val_loss: 0.0126 - val_accuracy: 0.9070\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.0122 - accuracy: 0.9059 - val_loss: 0.0112 - val_accuracy: 0.9160\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.0108 - accuracy: 0.9188 - val_loss: 0.0101 - val_accuracy: 0.9250\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 20s 325ms/step - loss: 0.0096 - accuracy: 0.9287 - val_loss: 0.0087 - val_accuracy: 0.9370\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.0087 - accuracy: 0.9340 - val_loss: 0.0096 - val_accuracy: 0.9250\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 0.0081 - accuracy: 0.9404 - val_loss: 0.0072 - val_accuracy: 0.9530\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 21s 327ms/step - loss: 0.0073 - accuracy: 0.9436 - val_loss: 0.0095 - val_accuracy: 0.9230\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.0088 - accuracy: 0.9331 - val_loss: 0.0061 - val_accuracy: 0.9570\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.0064 - accuracy: 0.9515 - val_loss: 0.0067 - val_accuracy: 0.9420\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.0059 - accuracy: 0.9555 - val_loss: 0.0054 - val_accuracy: 0.9560\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.0054 - accuracy: 0.9533 - val_loss: 0.0047 - val_accuracy: 0.9610\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.0049 - accuracy: 0.9574 - val_loss: 0.0043 - val_accuracy: 0.9640\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 21s 329ms/step - loss: 0.0047 - accuracy: 0.9570 - val_loss: 0.0043 - val_accuracy: 0.9600\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.0044 - accuracy: 0.9585 - val_loss: 0.0041 - val_accuracy: 0.9580\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.0043 - accuracy: 0.9589 - val_loss: 0.0035 - val_accuracy: 0.9640\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 21s 328ms/step - loss: 0.0040 - accuracy: 0.9602 - val_loss: 0.0037 - val_accuracy: 0.9620\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.0040 - accuracy: 0.9584 - val_loss: 0.0035 - val_accuracy: 0.9630\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 21s 330ms/step - loss: 0.0039 - accuracy: 0.9598 - val_loss: 0.0035 - val_accuracy: 0.9670\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 21s 331ms/step - loss: 0.0038 - accuracy: 0.9592 - val_loss: 0.0033 - val_accuracy: 0.9600\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 21s 333ms/step - loss: 0.0056 - accuracy: 0.9484 - val_loss: 0.0042 - val_accuracy: 0.9600\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 21s 332ms/step - loss: 0.0044 - accuracy: 0.9562 - val_loss: 0.0036 - val_accuracy: 0.9640\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.0038 - accuracy: 0.9589 - val_loss: 0.0030 - val_accuracy: 0.9680\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.0037 - accuracy: 0.9584 - val_loss: 0.0032 - val_accuracy: 0.9640\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.0035 - accuracy: 0.9603 - val_loss: 0.0029 - val_accuracy: 0.9690\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.0035 - accuracy: 0.9595 - val_loss: 0.0028 - val_accuracy: 0.9690\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.0033 - accuracy: 0.9605 - val_loss: 0.0028 - val_accuracy: 0.9690\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 21s 335ms/step - loss: 0.0032 - accuracy: 0.9600 - val_loss: 0.0032 - val_accuracy: 0.9640\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.0034 - accuracy: 0.9603 - val_loss: 0.0034 - val_accuracy: 0.9600\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 21s 338ms/step - loss: 0.0035 - accuracy: 0.9595 - val_loss: 0.0031 - val_accuracy: 0.9650\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 21s 334ms/step - loss: 0.0032 - accuracy: 0.9615 - val_loss: 0.0028 - val_accuracy: 0.9680\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 21s 337ms/step - loss: 0.0032 - accuracy: 0.9592 - val_loss: 0.0028 - val_accuracy: 0.9640\n",
      "Epoch 00048: early stopping\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 120\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(120))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(rnn_x_train, rnn_y_train, epochs=50, callbacks=[es], batch_size=128, validation_data=(rnn_x_val, rnn_y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 49ms/step - loss: 0.0656 - accuracy: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06555695086717606, 0.6718611121177673]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(rnn_x_test, rnn_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 빈도수 상위 5,000개의 단어만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "\n",
      "데이터 출력\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"\\n데이터 출력\")\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "# {'mdbl': 10996, 'fawc': 16260, 'degussa': 12089, ...}\n",
    "\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    \n",
    "# train 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "x_train = decoded\n",
    "\n",
    "# test 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "x_test = decoded\n",
    "\n",
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n",
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()  # DTM 생성\n",
    "tfidf_transformer = TfidfTransformer()  # TF-IDF 생성\n",
    "\n",
    "# train data\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(x_train_dtm.shape)\n",
    "print(tfidfv.shape)\n",
    "\n",
    "# test data\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report()\n",
    "- macro: 단순평균\n",
    "- weighted: 각 클래스에 속하는 표본의 개수로 가중평균\n",
    "- accuracy: 정확도. 전체 학습 데이터의 개수에서 클래스를 정확하게 맞춘 개수의 비율."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6731967943009796 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)    # 모델 학습\n",
    "\n",
    "predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted),'\\n') #예측값과 실제\n",
    "# print(classification_report(y_test, mod.predict(tfidfv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 시각화\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "    plt.ylabel('label')\n",
    "    plt.xlabel('predicted value')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph_confusion_matrix(mod, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 컴플리먼트 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8058771148708815\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 선형 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7666963490650045\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6179875333926982\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.701246660730187\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.767586821015138\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8161175422974176\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 2246\n",
      "max_len :  2376\n"
     ]
    }
   ],
   "source": [
    "(rnn_x_train, rnn_y_train), (rnn_x_test, rnn_y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "print(len(rnn_x_train), len(rnn_x_test))\n",
    "max_len = max(len(l) for l in np.concatenate((rnn_x_train, rnn_x_test), axis=0))\n",
    "print('max_len : ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_x_train = pad_sequences(rnn_x_train, maxlen=max_len)\n",
    "rnn_x_test = pad_sequences(rnn_x_test, maxlen=max_len)\n",
    "\n",
    "rnn_y_train = to_categorical(rnn_y_train, num_classes=46)\n",
    "rnn_y_test = to_categorical(rnn_y_test, num_classes=46)\n",
    "\n",
    "rnn_x_train = rnn_x_train[1000:]\n",
    "rnn_y_train = rnn_y_train[1000:]\n",
    "rnn_x_val = rnn_x_train[:1000]\n",
    "rnn_y_val = rnn_y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 14s 224ms/step - loss: 0.0780 - accuracy: 0.3374 - val_loss: 0.0692 - val_accuracy: 0.3260\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0623 - accuracy: 0.4560 - val_loss: 0.0613 - val_accuracy: 0.4730\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0577 - accuracy: 0.5005 - val_loss: 0.0571 - val_accuracy: 0.4870\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0524 - accuracy: 0.5401 - val_loss: 0.0515 - val_accuracy: 0.5600\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0513 - accuracy: 0.5472 - val_loss: 0.0501 - val_accuracy: 0.5680\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0488 - accuracy: 0.5730 - val_loss: 0.0493 - val_accuracy: 0.5960\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0553 - accuracy: 0.4865 - val_loss: 0.0515 - val_accuracy: 0.5490\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0477 - accuracy: 0.5857 - val_loss: 0.0477 - val_accuracy: 0.5910\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0465 - accuracy: 0.5900 - val_loss: 0.0467 - val_accuracy: 0.6000\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0441 - accuracy: 0.6186 - val_loss: 0.0435 - val_accuracy: 0.6250\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0421 - accuracy: 0.6436 - val_loss: 0.0438 - val_accuracy: 0.6570\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0411 - accuracy: 0.6530 - val_loss: 0.0429 - val_accuracy: 0.6290\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0387 - accuracy: 0.6701 - val_loss: 0.0389 - val_accuracy: 0.6830\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0365 - accuracy: 0.6963 - val_loss: 0.0375 - val_accuracy: 0.7020\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0345 - accuracy: 0.7159 - val_loss: 0.0342 - val_accuracy: 0.7340\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0329 - accuracy: 0.7278 - val_loss: 0.0328 - val_accuracy: 0.7370\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0306 - accuracy: 0.7478 - val_loss: 0.0327 - val_accuracy: 0.7350\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0285 - accuracy: 0.7622 - val_loss: 0.0285 - val_accuracy: 0.7660\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0301 - accuracy: 0.7484 - val_loss: 0.0338 - val_accuracy: 0.7320\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0281 - accuracy: 0.7647 - val_loss: 0.0281 - val_accuracy: 0.7820\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0256 - accuracy: 0.7917 - val_loss: 0.0266 - val_accuracy: 0.7860\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0240 - accuracy: 0.8073 - val_loss: 0.0240 - val_accuracy: 0.8170\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0223 - accuracy: 0.8260 - val_loss: 0.0226 - val_accuracy: 0.8260\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0202 - accuracy: 0.8435 - val_loss: 0.0208 - val_accuracy: 0.8410\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0204 - accuracy: 0.8429 - val_loss: 0.0216 - val_accuracy: 0.8460\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0193 - accuracy: 0.8502 - val_loss: 0.0191 - val_accuracy: 0.8580\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0174 - accuracy: 0.8677 - val_loss: 0.0177 - val_accuracy: 0.8650\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0164 - accuracy: 0.8742 - val_loss: 0.0162 - val_accuracy: 0.8830\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0150 - accuracy: 0.8865 - val_loss: 0.0150 - val_accuracy: 0.8890\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0137 - accuracy: 0.8988 - val_loss: 0.0146 - val_accuracy: 0.8890\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0130 - accuracy: 0.9067 - val_loss: 0.0137 - val_accuracy: 0.9050\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0124 - accuracy: 0.9090 - val_loss: 0.0142 - val_accuracy: 0.8950\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0120 - accuracy: 0.9117 - val_loss: 0.0143 - val_accuracy: 0.8990\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0116 - accuracy: 0.9146 - val_loss: 0.0120 - val_accuracy: 0.9170\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0107 - accuracy: 0.9236 - val_loss: 0.0115 - val_accuracy: 0.9200\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0098 - accuracy: 0.9292 - val_loss: 0.0110 - val_accuracy: 0.9200\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0091 - accuracy: 0.9374 - val_loss: 0.0100 - val_accuracy: 0.9320\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0085 - accuracy: 0.9402 - val_loss: 0.0094 - val_accuracy: 0.9300\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0080 - accuracy: 0.9439 - val_loss: 0.0088 - val_accuracy: 0.9450\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0078 - accuracy: 0.9434 - val_loss: 0.0084 - val_accuracy: 0.9450\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0073 - accuracy: 0.9455 - val_loss: 0.0080 - val_accuracy: 0.9450\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0076 - accuracy: 0.9422 - val_loss: 0.0086 - val_accuracy: 0.9370\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0074 - accuracy: 0.9471 - val_loss: 0.0074 - val_accuracy: 0.9420\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0064 - accuracy: 0.9516 - val_loss: 0.0070 - val_accuracy: 0.9510\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0060 - accuracy: 0.9525 - val_loss: 0.0066 - val_accuracy: 0.9570\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0062 - accuracy: 0.9516 - val_loss: 0.0064 - val_accuracy: 0.9550\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0059 - accuracy: 0.9557 - val_loss: 0.0063 - val_accuracy: 0.9550\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0055 - accuracy: 0.9565 - val_loss: 0.0060 - val_accuracy: 0.9560\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0053 - accuracy: 0.9567 - val_loss: 0.0060 - val_accuracy: 0.9560\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0051 - accuracy: 0.9567 - val_loss: 0.0057 - val_accuracy: 0.9550\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 120\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(120))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(rnn_x_train, rnn_y_train, epochs=50, callbacks=[es], batch_size=128, validation_data=(rnn_x_val, rnn_y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 43ms/step - loss: 0.0640 - accuracy: 0.6812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06397683173418045, 0.6812110543251038]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(rnn_x_test, rnn_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 직접 단어 갯수를 설정해서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "\n",
      "데이터 출력\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "\n",
    "# 데이터 출력\n",
    "print(\"\\n데이터 출력\")\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to <unk> growth and expansion plans for <unk> inc and <unk> inc over the next two years a and p said the acquisition of <unk> in august 1986 and <unk> in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt <unk> <unk> of west germany reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "# {'mdbl': 10996, 'fawc': 16260, 'degussa': 12089, ...}\n",
    "\n",
    "index_to_word = {index + 3 : word for word, index in word_index.items()}\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    \n",
    "# train 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "x_train = decoded\n",
    "\n",
    "# test 데이터 복원\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "x_test = decoded\n",
    "\n",
    "# 데이터 확인\n",
    "print(x_train[0])\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n",
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()  # DTM 생성\n",
    "tfidf_transformer = TfidfTransformer()  # TF-IDF 생성\n",
    "\n",
    "# train data\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(x_train_dtm.shape)\n",
    "print(tfidfv.shape)\n",
    "\n",
    "# test data\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_report()\n",
    "- macro: 단순평균\n",
    "- weighted: 각 클래스에 속하는 표본의 개수로 가중평균\n",
    "- accuracy: 정확도. 전체 학습 데이터의 개수에서 클래스를 정확하게 맞춘 개수의 비율."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6567230632235085 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = MultinomialNB()\n",
    "mod.fit(tfidfv, y_train)    # 모델 학습\n",
    "\n",
    "predicted = mod.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted),'\\n') #예측값과 실제\n",
    "# print(classification_report(y_test, mod.predict(tfidfv_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix 시각화\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "    df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "    plt.ylabel('label')\n",
    "    plt.xlabel('predicted value')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "graph_confusion_matrix(mod, tfidfv_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 컴플리먼트 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7707034728406055\n"
     ]
    }
   ],
   "source": [
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 로지스틱 회귀(Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8076580587711487\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=10000, penalty='l2')\n",
    "lr.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 선형 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7813891362422084\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 결정 트리(Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.6202137132680321\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 랜덤 포레스트(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.674087266251113\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) 그래디언트 부스팅 트리(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.7666963490650045\n"
     ]
    }
   ],
   "source": [
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) 보팅(Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8116651825467498\n"
     ]
    }
   ],
   "source": [
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft', n_jobs=-1)\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "print(\"정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 2246\n",
      "max_len :  2376\n"
     ]
    }
   ],
   "source": [
    "(rnn_x_train, rnn_y_train), (rnn_x_test, rnn_y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "print(len(rnn_x_train), len(rnn_x_test))\n",
    "max_len = max(len(l) for l in np.concatenate((rnn_x_train, rnn_x_test), axis=0))\n",
    "print('max_len : ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_x_train = pad_sequences(rnn_x_train, maxlen=max_len)\n",
    "rnn_x_test = pad_sequences(rnn_x_test, maxlen=max_len)\n",
    "\n",
    "rnn_y_train = to_categorical(rnn_y_train, num_classes=46)\n",
    "rnn_y_test = to_categorical(rnn_y_test, num_classes=46)\n",
    "\n",
    "rnn_x_train = rnn_x_train[1000:]\n",
    "rnn_y_train = rnn_y_train[1000:]\n",
    "rnn_x_val = rnn_x_train[:1000]\n",
    "rnn_y_val = rnn_y_train[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30982\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 14s 225ms/step - loss: 0.0789 - accuracy: 0.3480 - val_loss: 0.0733 - val_accuracy: 0.3260\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 220ms/step - loss: 0.0639 - accuracy: 0.4464 - val_loss: 0.0612 - val_accuracy: 0.4760\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 220ms/step - loss: 0.0591 - accuracy: 0.5016 - val_loss: 0.0591 - val_accuracy: 0.4890\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 220ms/step - loss: 0.0557 - accuracy: 0.5207 - val_loss: 0.0565 - val_accuracy: 0.5200\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0524 - accuracy: 0.5390 - val_loss: 0.0514 - val_accuracy: 0.5490\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0486 - accuracy: 0.5738 - val_loss: 0.0499 - val_accuracy: 0.5800\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0493 - accuracy: 0.5826 - val_loss: 0.0486 - val_accuracy: 0.5900\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0463 - accuracy: 0.6046 - val_loss: 0.0460 - val_accuracy: 0.6210\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0428 - accuracy: 0.6436 - val_loss: 0.0422 - val_accuracy: 0.6510\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0397 - accuracy: 0.6718 - val_loss: 0.0385 - val_accuracy: 0.6870\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0373 - accuracy: 0.6941 - val_loss: 0.0364 - val_accuracy: 0.7050\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0342 - accuracy: 0.7190 - val_loss: 0.0344 - val_accuracy: 0.7130\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0313 - accuracy: 0.7395 - val_loss: 0.0335 - val_accuracy: 0.7160\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0292 - accuracy: 0.7602 - val_loss: 0.0292 - val_accuracy: 0.7700\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0261 - accuracy: 0.7888 - val_loss: 0.0252 - val_accuracy: 0.7880\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0280 - accuracy: 0.7735 - val_loss: 0.0281 - val_accuracy: 0.7700\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0245 - accuracy: 0.8001 - val_loss: 0.0222 - val_accuracy: 0.8090\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0208 - accuracy: 0.8284 - val_loss: 0.0192 - val_accuracy: 0.8380\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0184 - accuracy: 0.8513 - val_loss: 0.0168 - val_accuracy: 0.8610\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.0166 - accuracy: 0.8676 - val_loss: 0.0152 - val_accuracy: 0.8880\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0147 - accuracy: 0.8842 - val_loss: 0.0133 - val_accuracy: 0.9010\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0133 - accuracy: 0.8986 - val_loss: 0.0118 - val_accuracy: 0.9130\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0121 - accuracy: 0.9075 - val_loss: 0.0103 - val_accuracy: 0.9150\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0108 - accuracy: 0.9176 - val_loss: 0.0102 - val_accuracy: 0.9300\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0099 - accuracy: 0.9232 - val_loss: 0.0090 - val_accuracy: 0.9300\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0090 - accuracy: 0.9316 - val_loss: 0.0077 - val_accuracy: 0.9400\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0081 - accuracy: 0.9387 - val_loss: 0.0068 - val_accuracy: 0.9540\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0077 - accuracy: 0.9381 - val_loss: 0.0062 - val_accuracy: 0.9550\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0068 - accuracy: 0.9439 - val_loss: 0.0061 - val_accuracy: 0.9480\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0063 - accuracy: 0.9488 - val_loss: 0.0058 - val_accuracy: 0.9480\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0060 - accuracy: 0.9511 - val_loss: 0.0053 - val_accuracy: 0.9570\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 14s 224ms/step - loss: 0.0054 - accuracy: 0.9540 - val_loss: 0.0054 - val_accuracy: 0.9510\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0055 - accuracy: 0.9511 - val_loss: 0.0054 - val_accuracy: 0.9560\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 14s 223ms/step - loss: 0.0054 - accuracy: 0.9536 - val_loss: 0.0052 - val_accuracy: 0.9520\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0053 - accuracy: 0.9523 - val_loss: 0.0047 - val_accuracy: 0.9560\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 14s 226ms/step - loss: 0.0047 - accuracy: 0.9572 - val_loss: 0.0040 - val_accuracy: 0.9610\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 14s 227ms/step - loss: 0.0043 - accuracy: 0.9585 - val_loss: 0.0042 - val_accuracy: 0.9640\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0042 - accuracy: 0.9579 - val_loss: 0.0037 - val_accuracy: 0.9640\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0041 - accuracy: 0.9587 - val_loss: 0.0040 - val_accuracy: 0.9620\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0039 - accuracy: 0.9607 - val_loss: 0.0032 - val_accuracy: 0.9660\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0037 - accuracy: 0.9600 - val_loss: 0.0033 - val_accuracy: 0.9680\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0036 - accuracy: 0.9597 - val_loss: 0.0030 - val_accuracy: 0.9690\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0037 - accuracy: 0.9603 - val_loss: 0.0032 - val_accuracy: 0.9590\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0037 - accuracy: 0.9587 - val_loss: 0.0030 - val_accuracy: 0.9680\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 14s 224ms/step - loss: 0.0035 - accuracy: 0.9577 - val_loss: 0.0030 - val_accuracy: 0.9670\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 14s 223ms/step - loss: 0.0033 - accuracy: 0.9614 - val_loss: 0.0028 - val_accuracy: 0.9660\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0033 - accuracy: 0.9592 - val_loss: 0.0032 - val_accuracy: 0.9620\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 0.0036 - accuracy: 0.9590 - val_loss: 0.0035 - val_accuracy: 0.9630\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 14s 223ms/step - loss: 0.0034 - accuracy: 0.9602 - val_loss: 0.0029 - val_accuracy: 0.9670\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 14s 224ms/step - loss: 0.0033 - accuracy: 0.9595 - val_loss: 0.0031 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(index_to_word)\n",
    "print(vocab_size)\n",
    "word_vector_dim = 120\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim))\n",
    "model.add(keras.layers.LSTM(120))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))\n",
    "# 모델 훈련\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(rnn_x_train, rnn_y_train, epochs=50, callbacks=[es], batch_size=128, validation_data=(rnn_x_val, rnn_y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 3s 43ms/step - loss: 0.0671 - accuracy: 0.6817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06705751270055771, 0.6816563010215759]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(rnn_x_test, rnn_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model|None|5000|10000|\n",
    "|:-|:-|:-|:-|\n",
    "|나이브 베이즈 분류기|0.59|0.67|0.65|\n",
    "|컴플리먼트 나이브 베이즈 분류기|0.76|0.77|0.77|\n",
    "|로지스틱 회귀|0.81|0.80|0.80|\n",
    "|서포트 벡터 머신|0.77|0.76|0.78|\n",
    "|결정 트리|0.62|0.61|0.62|\n",
    "|랜덤 포레스트|0.65|0.70|0.67|\n",
    "|그래디언트 부스팅 트리|0.77|0.76|0.76|\n",
    "|보팅|0.81|0.81|0.81|\n",
    "|RNN|0.67|0.68|0.68|\n",
    "\n",
    "단어 개수에 따라 어느 정도 차이를 보일 줄 알았는데 생각보다 큰 차이가 없었다. 그나마 나이브 베이즈 분류기로 해석해보자면 나이브 베이즈 분류는 통계적 분류 기법이기 때문에 모든 단어를 사전화하는 것보다 상위 n개를 사전화하는 것이 성능이 더 좋게 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "루브릭\n",
    "\n",
    "|평가문항|상세기준|\n",
    "|:-|:-|\n",
    "|1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가?|3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.|\n",
    "|2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가?|Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.|\n",
    "|3. 생성모델의 metric(BLEU 등) 기준 이상 높은 성능이 확인되었는가?|동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 각 모델마다 단어수에 따른 차이가 크지 않아서 생각보다 놀랐다.\n",
    "- RNN은 오버피팅되었는데 나중에 다시 수정해봐야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
